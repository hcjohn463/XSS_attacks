import os
import csv
import faiss
import numpy as np
from transformers import AutoTokenizer, AutoModel
import torch
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score
from tqdm import tqdm
import warnings
import time

warnings.filterwarnings("ignore")

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")


# ğŸ”¹ 1. é¸æ“‡åµŒå…¥æ¨¡å‹ï¼ˆå»ºè­°ç”¨ BGE-M3 æˆ– Sentence-BERTï¼‰
# model_name = "BAAI/bge-small-en"  
# model_name = "sentence-transformers/all-MiniLM-L6-v2"
model_name = 'microsoft/codebert-base'
# model_name = "jackaduma/SecBERT"
# model_name = "cssupport/mobilebert-sql-injection-detect"
# model_name = "roberta-base-openai-detector"

testing = "XSS_dataset_testing_13636"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name).to(device)  # ğŸš€ æŠŠæ¨¡å‹ç§»å‹•åˆ° GPU

model_filename = model_name.replace('-', '_').replace('/', '_')

print(f"æ­£åœ¨ä½¿ç”¨ {model_name} æ¨¡å‹é€²è¡Œ XSS æª¢æ¸¬...")

# ğŸ”¹ 2. è¨­å®š XSS å‘é‡è³‡æ–™åº«ç›®éŒ„
base_output_dir = "D:/RAG/xss_attacks/result/retrieval"
os.makedirs(base_output_dir, exist_ok=True)

# ğŸ”¹ 3. åŠ è¼‰ FAISS å‘é‡ç´¢å¼• & æ¨™ç±¤
base_vector_dir = "D:/RAG/xss_attacks/dataset/vector"
model_vector_dir = os.path.join(base_vector_dir, model_filename)

index_file = os.path.join(model_vector_dir, f"xss_vector_index_{model_filename}.faiss")
labels_file = os.path.join(model_vector_dir, f"xss_labels_{model_filename}.npy")
payloads_file = os.path.join(model_vector_dir, f"xss_payloads_{model_filename}.npy")

print(f"ğŸ“¥ åŠ è¼‰ XSS å‘é‡åº«ï¼ˆ{index_file}ï¼‰...")
index = faiss.read_index(index_file)
labels = np.load(labels_file)
payloads = np.load(payloads_file, allow_pickle=True)

print(f"âœ… å‘é‡ç´¢å¼•ä¸­åŒ…å« {index.ntotal} æ¢ XSS Payloadsã€‚")


# ğŸ”¹ 4. å®šç¾© XSS Payload åµŒå…¥å‡½æ•¸
def get_embedding(text):
    inputs = tokenizer(
        text, 
        return_tensors="pt", 
        padding=True, 
        truncation=True,  # æˆªæ–·éé•·çš„è¼¸å…¥
        max_length=512  # é™åˆ¶æœ€å¤§é•·åº¦ç‚º 512
    ).to(device)
    with torch.no_grad():
        outputs = model(**inputs)
    hidden_states = outputs.last_hidden_state
    sentence_embedding = hidden_states.mean(dim=1).squeeze().cpu().numpy()  
    return sentence_embedding


# ğŸ”¹ 5. å®šç¾© XSS æª¢æ¸¬å‡½æ•¸
def classify_xss_risk(user_input, k=5):
    """
    åˆ¤æ–· XSS Payload çš„é¢¨éšªã€‚
    """
    # åµŒå…¥ç”¨æˆ¶è¼¸å…¥
    input_embedding = get_embedding(user_input)

    # æŸ¥è©¢å‘é‡æ­£è¦åŒ–
    normalized_query = input_embedding / np.linalg.norm(input_embedding, keepdims=True)

    # æª¢ç´¢ FAISS
    distances, indices = index.search(np.array([normalized_query], dtype="float32"), k)

    # è¨ˆç®—åˆ†æ•¸
    scores = {0: 0, 1: 0}  # 0 = benign (åˆæ³•), 1 = malicious (æƒ¡æ„)
    valid_results = []
    for idx, dist in zip(indices[0], distances[0]):
        scores[labels[idx]] += dist
        valid_results.append({
            "index": int(idx),
            "label": int(labels[idx]),
            "distance": round(float(dist), 4),
            "payload": payloads[idx]
        })
    
    # åˆ¤æ–·èªå¥åˆæ³•æ€§
    classification = "benign" if scores[0] > scores[1] else "malicious"

    return {
        "input_payload": user_input,
        "classification": classification,
        "reason": f"Scores: {{'benign': {scores[0]:.4f}, 'malicious': {scores[1]:.4f}}}",
        "details": valid_results
    }

# ğŸ”¹ 6. è®€å–æ¸¬è©¦æ•¸æ“š
input_file = f"D:/RAG/xss_attacks/dataset/{testing}.csv"
print(f"ğŸ“¥ è®€å–æ¸¬è©¦æ•¸æ“š: {input_file}...")
with open(input_file, "r", encoding="ISO-8859-1") as csvfile:
    reader = csv.DictReader(csvfile)
    data = list(reader)
    print(f"âœ… å…±è®€å–åˆ° {len(data)} ç­† XSS æ¸¬è©¦æ•¸æ“šã€‚")

# ğŸ”¹ 7. è¨­å®šä¸åŒ `k` å€¼æ¸¬è©¦
all_results = []
for k_value in range(1, 6):
    print(f"ğŸ” æ­£åœ¨æ¸¬è©¦ k = {k_value} ...")

    # è¨­ç½®è¼¸å‡ºè³‡æ–™å¤¾
    model_output_dir = os.path.join(base_output_dir, model_filename, f"k_{k_value}")
    os.makedirs(model_output_dir, exist_ok=True)

    # è¨­å®šè¼¸å‡ºæ–‡ä»¶
    output_file = os.path.join(model_output_dir, f"testing_results_k_{k_value}.csv")
    confusion_matrix_file = os.path.join(model_output_dir, f"confusion_matrix_k_{k_value}.png")
    summary_file = os.path.join(base_output_dir, model_filename, "summary_results.txt")

    results = []
    true_labels = []
    predicted_labels = []

    start_time = time.time()

    # è™•ç†æ¯ç­† XSS æ¸¬è©¦æ•¸æ“š
    for row in tqdm(data, desc="è™•ç†æ¸¬è©¦æ•¸æ“š", unit="ç­†"):
        user_payload = row["Payload"]
        true_label = int(row["Label"])  # 0 = åˆæ³•, 1 = æƒ¡æ„

        # åˆ¤æ–· XSS é¢¨éšª
        result = classify_xss_risk(user_payload, k=k_value)

        # è½‰æ›æ¨™ç±¤æ ¼å¼
        mapped_label = {"benign": 0, "malicious": 1}

        results.append({
            "payload": user_payload,
            "true_label": true_label,
            "predicted_label": mapped_label[result["classification"]],
            "reason": result["reason"]
        })
        true_labels.append(true_label)
        predicted_labels.append(mapped_label[result["classification"]])

    # è¨ˆç®—æ™‚é–“
    total_time = time.time() - start_time
    average_time = (total_time / len(data)) * 1000  # ms

    # è¨ˆç®— Accuracy, Precision, Recall
    accuracy = accuracy_score(true_labels, predicted_labels) * 100
    precision = precision_score(true_labels, predicted_labels) * 100
    recall = recall_score(true_labels, predicted_labels) * 100

    all_results.append({
        "k": k_value,
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "total_time": total_time,
        "average_time": average_time
    })

    # å­˜å…¥ CSV
    print(f"ğŸ“„ å¯«å…¥çµæœåˆ° {output_file}...")
    with open(output_file, "w", newline="", encoding="utf-8", errors="replace") as csvfile:
        fieldnames = ["payload", "true_label", "predicted_label", "reason"]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(results)

    # **ç¹ªè£½æ··æ·†çŸ©é™£**
    cm = confusion_matrix(true_labels, predicted_labels, labels=[0, 1])
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["benign", "malicious"])
    disp.plot(cmap=plt.cm.Blues, colorbar=False, values_format='.0f')
    plt.title(f"XSS Detection: {model_name} - k = {k_value}")
    plt.savefig(confusion_matrix_file)
    print(f"âœ… æ··æ·†çŸ©é™£å·²ä¿å­˜: {confusion_matrix_file}")

# ğŸš€ å„²å­˜ summary çµæœ
with open(summary_file, "w", encoding="utf-8") as f:
    for result in all_results:
        f.write(f"k = {result['k']}\n")
        f.write(f"Accuracy: {result['accuracy']:.3f}%\n")
        f.write(f"Precision: {result['precision']:.3f}%\n")
        f.write(f"Recall: {result['recall']:.3f}%\n")
        f.write(f"Total Time: {result['total_time']:.2f}s\n")
        f.write(f"Average Time: {result['average_time']:.2f}ms\n\n")

print(f"âœ… æ‰€æœ‰çµæœå·²ä¿å­˜åˆ° {summary_file}ï¼ğŸš€")
