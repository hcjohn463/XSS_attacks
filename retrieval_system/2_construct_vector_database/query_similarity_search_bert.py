import os
import faiss
import numpy as np
import json
from transformers import AutoTokenizer, AutoModel
import torch

# ğŸ”¹ 1. é¸æ“‡ NLP æ¨¡å‹ï¼ˆå»ºè­°ç”¨ BGE-M3 æˆ– Sentence-BERTï¼‰
model_name = "BAAI/bge-small-en"  # æˆ– "sentence-transformers/all-MiniLM-L6-v2"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

# ğŸ”¹ 2. è¨­å®š XSS å‘é‡è³‡æ–™åº«ç›®éŒ„
base_dir = "D:/RAG/xss_attacks/dataset/vector"
model_dir = os.path.join(base_dir, model_name.replace('-', '_').replace('/', '_'))

# è¨­å®š FAISS è·¯å¾‘
index_file = os.path.join(model_dir, "xss_vector_index.faiss")
labels_file = os.path.join(model_dir, "xss_labels.npy")
payloads_file = os.path.join(model_dir, "xss_payloads.npy")

# ğŸ”¹ 3. åŠ è¼‰ FAISS å‘é‡ç´¢å¼• & æ¨™ç±¤
print(f"ğŸ“¥ åŠ è¼‰ XSS å‘é‡åº«ï¼ˆ{index_file}ï¼‰...")
index = faiss.read_index(index_file)
labels = np.load(labels_file)
payloads = np.load(payloads_file, allow_pickle=True)

print(f"âœ… å‘é‡ç´¢å¼•ä¸­åŒ…å« {index.ntotal} æ¢ XSS Payloadsã€‚")

# ğŸ”¹ 4. å®šç¾© XSS Payload åµŒå…¥å‡½æ•¸
def get_embedding(text):
    """
    è½‰æ› XSS Payload æˆå‘é‡
    """
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    with torch.no_grad():
        outputs = model(**inputs)
    hidden_states = outputs.last_hidden_state
    sentence_embedding = hidden_states.mean(dim=1).squeeze().numpy()
    return sentence_embedding

# ğŸ”¹ 5. å®šç¾© XSS æª¢ç´¢å‡½æ•¸
def retrieve_xss_risk(user_input, k=3):
    """
    æª¢ç´¢ XSS é¢¨éšªï¼Œè¿”å›æœ€ç›¸ä¼¼çš„æ”»æ“Šå­—ä¸²ã€‚
    
    Args:
        user_input (str): ç”¨æˆ¶è¼¸å…¥çš„ HTML/JavaScript å…§å®¹ã€‚
        k (int): è¿”å›çš„æœ€ç›¸ä¼¼ XSS Payload æ•¸é‡ã€‚
    
    Returns:
        list: åŒ…å«æª¢ç´¢åˆ°çš„ç´¢å¼•ã€æ¨™ç±¤ã€è·é›¢å’Œ XSS Payloadã€‚
    """
    print(f"\nğŸ› ï¸ æª¢æ¸¬ XSS é¢¨éšª: {user_input}")
    
    # åµŒå…¥ç”¨æˆ¶è¼¸å…¥
    input_embedding = get_embedding(user_input)
    
    # æª¢ç´¢ FAISS
    distances, indices = index.search(np.array([input_embedding], dtype="float32"), k)
    
    # è¿”å›çµæœ
    results = []
    print(f"\nğŸ” æœ€ç›¸ä¼¼çš„ {k} å€‹ XSS Payloadsï¼š")
    for i, idx in enumerate(indices[0]):
        result = {
            "index": int(idx),
            "label": int(labels[idx]),  # 0 = åˆæ³•, 1 = éæ³•
            "distance": float(distances[0][i]),
            "payload": payloads[idx]  # XSS Payload
        }
        results.append(result)
        print(f"- XSS Payload: {result['payload']}, æ¨™ç±¤: {result['label']}, è·é›¢: {result['distance']}")
    
    return results

# ğŸ”¹ 6. æ¸¬è©¦ XSS æª¢ç´¢
test_input = "<img src=x onerror=alert('XSS')>"
result = retrieve_xss_risk(test_input, k=3)

# ğŸ”¹ 7. æ‰“å°è©³ç´°çµæœ
print("\nğŸ“Š è©³ç´°çµæœï¼š")
for i, res in enumerate(result, start=1):
    print(f"ç¬¬ {i} ç­†ï¼š")
    print(f"  - ç´¢å¼•: {res['index']}")
    print(f"  - æ¨™ç±¤: {res['label']} (0=åˆæ³•, 1=éæ³•)")
    print(f"  - è·é›¢: {res['distance']}")
    print(f"  - ç›¸ä¼¼ XSS Payload: {res['payload']}")

print("\nâœ… XSS æª¢æ¸¬å®Œæˆï¼ğŸš€")
